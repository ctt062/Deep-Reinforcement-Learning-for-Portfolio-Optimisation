{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c3b4627",
   "metadata": {},
   "source": [
    "# Deep Reinforcement Learning for Portfolio Optimization\n",
    "\n",
    "**IEDA4000F - Deep Learning for Decision Analytics**  \n",
    "**The Hong Kong University of Science and Technology (HKUST)**\n",
    "\n",
    "---\n",
    "\n",
    "This notebook demonstrates the complete pipeline for training and evaluating DRL agents for portfolio optimization.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup and Data Loading](#1-setup-and-data-loading)\n",
    "2. [Environment Creation](#2-environment-creation)\n",
    "3. [Training DRL Agents](#3-training-drl-agents)\n",
    "4. [Running Benchmarks](#4-running-benchmarks)\n",
    "5. [Performance Evaluation](#5-performance-evaluation)\n",
    "6. [Visualization and Analysis](#6-visualization-and-analysis)\n",
    "7. [Conclusions](#7-conclusions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942d4829",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9546761f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "from src.data_loader import DataLoader\n",
    "from src.portfolio_env import PortfolioEnv\n",
    "from src.agents import create_agent, train_agent\n",
    "from src.benchmarks import run_all_benchmarks\n",
    "from src.metrics import PerformanceMetrics, compare_strategies\n",
    "from src.visualization import *\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"✓ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f738c718",
   "metadata": {},
   "source": [
    "### 1.1 Define Asset Universe and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bf9cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define assets for portfolio\n",
    "ASSETS = ['AAPL', 'NVDA', 'TSLA', 'MSFT', 'GOOGL', 'AMZN', 'SPY', 'GLD']\n",
    "\n",
    "# Date range\n",
    "START_DATE = '2015-01-01'\n",
    "END_DATE = '2024-12-31'\n",
    "\n",
    "# Training parameters\n",
    "TRAIN_RATIO = 0.7\n",
    "TRANSACTION_COST = 0.001  # 0.1%\n",
    "INITIAL_BALANCE = 100000.0\n",
    "\n",
    "print(f\"Asset Universe: {ASSETS}\")\n",
    "print(f\"Number of Assets: {len(ASSETS)}\")\n",
    "print(f\"Date Range: {START_DATE} to {END_DATE}\")\n",
    "print(f\"Transaction Cost: {TRANSACTION_COST*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eccf1d6",
   "metadata": {},
   "source": [
    "### 1.2 Download and Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd23c910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data loader\n",
    "loader = DataLoader(\n",
    "    assets=ASSETS,\n",
    "    start_date=START_DATE,\n",
    "    end_date=END_DATE,\n",
    "    data_dir='../data'\n",
    ")\n",
    "\n",
    "# Download data\n",
    "print(\"Downloading data from Yahoo Finance...\")\n",
    "prices = loader.download_data()\n",
    "\n",
    "print(f\"\\nData shape: {prices.shape}\")\n",
    "print(f\"Date range: {prices.index[0]} to {prices.index[-1]}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb66d3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute returns\n",
    "returns, log_returns = loader.compute_returns()\n",
    "\n",
    "print(f\"Returns shape: {returns.shape}\")\n",
    "print(f\"\\nBasic statistics:\")\n",
    "print(returns.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f60274",
   "metadata": {},
   "source": [
    "### 1.3 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc9d7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build features with technical indicators\n",
    "print(\"Building features with technical indicators...\")\n",
    "features = loader.build_features(\n",
    "    sma_periods=[5, 10, 20],\n",
    "    ema_periods=[5, 10, 20],\n",
    "    momentum_periods=[5, 10, 20],\n",
    "    include_volatility=True,\n",
    "    normalize=True,\n",
    "    normalize_method='zscore',\n",
    "    rolling_window=60\n",
    ")\n",
    "\n",
    "print(f\"\\nFeature set shape: {features.shape}\")\n",
    "print(f\"Number of features: {features.shape[1]}\")\n",
    "print(f\"\\nFeature columns (first 10):\")\n",
    "print(features.columns[:10].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604b967a",
   "metadata": {},
   "source": [
    "### 1.4 Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8a6f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "train_data, test_data = loader.train_test_split(train_ratio=TRAIN_RATIO)\n",
    "\n",
    "print(\"Data split summary:\")\n",
    "print(f\"Train period: {train_data['prices'].index[0]} to {train_data['prices'].index[-1]}\")\n",
    "print(f\"Train samples: {len(train_data['prices'])}\")\n",
    "print(f\"\\nTest period: {test_data['prices'].index[0]} to {test_data['prices'].index[-1]}\")\n",
    "print(f\"Test samples: {len(test_data['prices'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dc851a",
   "metadata": {},
   "source": [
    "### 1.5 Asset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8079616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get asset statistics\n",
    "stats = loader.get_asset_statistics()\n",
    "\n",
    "print(\"Asset Statistics:\")\n",
    "print(stats.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8213fb2",
   "metadata": {},
   "source": [
    "## 2. Environment Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375e262a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training environment\n",
    "train_env = PortfolioEnv(\n",
    "    prices=train_data['prices'],\n",
    "    returns=train_data['returns'],\n",
    "    features=train_data['features'],\n",
    "    initial_balance=INITIAL_BALANCE,\n",
    "    transaction_cost=TRANSACTION_COST,\n",
    "    lookback_window=20,\n",
    "    reward_type='risk_adjusted',\n",
    "    risk_penalty_lambda=0.5,\n",
    "    allow_short=False,\n",
    ")\n",
    "\n",
    "print(\"Training Environment:\")\n",
    "print(f\"  Number of assets: {train_env.n_assets}\")\n",
    "print(f\"  Max steps: {train_env.max_steps}\")\n",
    "print(f\"  Observation space: {train_env.observation_space.shape}\")\n",
    "print(f\"  Action space: {train_env.action_space.shape}\")\n",
    "print(f\"  Transaction cost: {train_env.transaction_cost*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3e25a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test environment with random actions\n",
    "print(\"Testing environment with random actions...\")\n",
    "obs, info = train_env.reset()\n",
    "print(f\"Initial observation shape: {obs.shape}\")\n",
    "print(f\"Initial portfolio value: ${info['portfolio_value']:,.2f}\")\n",
    "\n",
    "# Take a few random steps\n",
    "for i in range(5):\n",
    "    action = train_env.action_space.sample()\n",
    "    obs, reward, terminated, truncated, info = train_env.step(action)\n",
    "    print(f\"Step {i+1}: Reward={reward:.4f}, Value=${info['portfolio_value']:,.2f}, Turnover={info['turnover']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19152369",
   "metadata": {},
   "source": [
    "## 3. Training DRL Agents\n",
    "\n",
    "We'll train PPO (Proximal Policy Optimization) agent, which is well-suited for continuous action spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f368287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PPO agent\n",
    "print(\"Creating PPO agent...\")\n",
    "ppo_agent = create_agent(\n",
    "    agent_type='ppo',\n",
    "    env=train_env,\n",
    "    learning_rate=0.0003,\n",
    "    n_steps=2048,\n",
    "    batch_size=64,\n",
    "    n_epochs=10,\n",
    "    gamma=0.99,\n",
    "    gae_lambda=0.95,\n",
    "    clip_range=0.2,\n",
    "    ent_coef=0.01,\n",
    "    net_arch=[128, 128],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"✓ PPO agent created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61455370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train PPO agent\n",
    "# Note: Use fewer timesteps for quick demo. Increase for better performance.\n",
    "TRAIN_TIMESTEPS = 50000  # Increase to 100000+ for production\n",
    "\n",
    "print(f\"Training PPO agent for {TRAIN_TIMESTEPS} timesteps...\")\n",
    "print(\"This may take several minutes...\\n\")\n",
    "\n",
    "ppo_agent.learn(total_timesteps=TRAIN_TIMESTEPS, log_interval=10)\n",
    "\n",
    "print(\"\\n✓ Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47ab8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "model_path = '../models/ppo_demo.zip'\n",
    "ppo_agent.save(model_path)\n",
    "print(f\"Model saved to: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa85acb",
   "metadata": {},
   "source": [
    "## 4. Running Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48f1abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run benchmark strategies on test data\n",
    "print(\"Running benchmark strategies on test data...\")\n",
    "\n",
    "benchmark_results = run_all_benchmarks(\n",
    "    returns=test_data['returns'],\n",
    "    transaction_cost=TRANSACTION_COST,\n",
    "    initial_value=INITIAL_BALANCE,\n",
    "    mv_lookback=60,\n",
    "    momentum_lookback=20,\n",
    "    momentum_top_k=3,\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Benchmark strategies completed!\")\n",
    "print(f\"\\nBenchmarks run: {list(benchmark_results.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ecd8ea",
   "metadata": {},
   "source": [
    "## 5. Performance Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c379c7c",
   "metadata": {},
   "source": [
    "### 5.1 Evaluate PPO Agent on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f842f19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test environment\n",
    "test_env = PortfolioEnv(\n",
    "    prices=test_data['prices'],\n",
    "    returns=test_data['returns'],\n",
    "    features=test_data['features'],\n",
    "    initial_balance=INITIAL_BALANCE,\n",
    "    transaction_cost=TRANSACTION_COST,\n",
    "    lookback_window=20,\n",
    "    reward_type='risk_adjusted',\n",
    "    risk_penalty_lambda=0.5,\n",
    "    allow_short=False,\n",
    ")\n",
    "\n",
    "# Evaluate PPO agent\n",
    "print(\"Evaluating PPO agent on test set...\")\n",
    "obs, info = test_env.reset()\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    action, _ = ppo_agent.predict(obs, deterministic=True)\n",
    "    obs, reward, terminated, truncated, info = test_env.step(action)\n",
    "    done = terminated or truncated\n",
    "\n",
    "# Get PPO results\n",
    "ppo_history = test_env.get_portfolio_history()\n",
    "ppo_results = {\n",
    "    'returns': ppo_history['returns'],\n",
    "    'values': ppo_history['values'],\n",
    "    'weights': ppo_history['weights'],\n",
    "    'turnover': ppo_history['turnover'],\n",
    "}\n",
    "\n",
    "print(f\"✓ PPO evaluation completed!\")\n",
    "print(f\"Final portfolio value: ${ppo_results['values'][-1]:,.2f}\")\n",
    "print(f\"Total return: {(ppo_results['values'][-1]/INITIAL_BALANCE - 1)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a7c293",
   "metadata": {},
   "source": [
    "### 5.2 Compare All Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd81fbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all results\n",
    "all_results = {'PPO': ppo_results, **benchmark_results}\n",
    "\n",
    "# Calculate metrics\n",
    "metrics_df = compare_strategies(\n",
    "    all_results,\n",
    "    risk_free_rate=0.02,\n",
    "    periods_per_year=252\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Performance Metrics Comparison\")\n",
    "print(\"=\"*80)\n",
    "print(metrics_df.to_string())\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996e4a4f",
   "metadata": {},
   "source": [
    "### 5.3 Detailed Metrics for Each Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d314ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print detailed metrics\n",
    "for name, data in all_results.items():\n",
    "    metrics = PerformanceMetrics(\n",
    "        returns=data['returns'],\n",
    "        values=data['values'],\n",
    "        weights=data.get('weights'),\n",
    "        turnover=data.get('turnover'),\n",
    "        risk_free_rate=0.02,\n",
    "        periods_per_year=252\n",
    "    )\n",
    "    metrics.print_metrics(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdc7323",
   "metadata": {},
   "source": [
    "## 6. Visualization and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46de75c2",
   "metadata": {},
   "source": [
    "### 6.1 Cumulative Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c03eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cumulative returns\n",
    "returns_dict = {name: data['returns'] for name, data in all_results.items()}\n",
    "plot_cumulative_returns(returns_dict, figsize=(14, 7))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868c24ee",
   "metadata": {},
   "source": [
    "### 6.2 Portfolio Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a043591e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot portfolio values\n",
    "values_dict = {name: data['values'] for name, data in all_results.items()}\n",
    "plot_portfolio_values(values_dict, figsize=(14, 7))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7839f3df",
   "metadata": {},
   "source": [
    "### 6.3 Return Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c5b2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot return distributions\n",
    "plot_return_distribution(returns_dict, figsize=(14, 6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b4d896",
   "metadata": {},
   "source": [
    "### 6.4 Performance Metrics Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b68d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot metrics comparison\n",
    "plot_metrics_comparison(metrics_df, figsize=(16, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12677718",
   "metadata": {},
   "source": [
    "### 6.5 Drawdown Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdc332d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot drawdown for PPO agent\n",
    "plot_drawdown(ppo_results['values'], title=\"Drawdown Analysis - PPO Agent\", figsize=(14, 8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e65ffb",
   "metadata": {},
   "source": [
    "### 6.6 Portfolio Allocation Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb578ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PPO agent's portfolio allocation\n",
    "plot_weights_stacked(\n",
    "    ppo_results['weights'],\n",
    "    test_data['prices'].columns.tolist(),\n",
    "    title=\"PPO Agent - Portfolio Allocation Over Time\",\n",
    "    figsize=(14, 7)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a15d6b",
   "metadata": {},
   "source": [
    "### 6.7 Turnover Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2c466a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot turnover analysis\n",
    "turnover_dict = {name: data['turnover'] for name, data in all_results.items() if 'turnover' in data}\n",
    "plot_turnover_analysis(turnover_dict, figsize=(14, 6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4695a02b",
   "metadata": {},
   "source": [
    "## 7. Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd78d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY AND CONCLUSIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. Best Performing Strategy (by Sharpe Ratio):\")\n",
    "best_sharpe = metrics_df['Sharpe Ratio'].idxmax()\n",
    "print(f\"   Strategy: {best_sharpe}\")\n",
    "print(f\"   Sharpe Ratio: {metrics_df.loc[best_sharpe, 'Sharpe Ratio']:.4f}\")\n",
    "print(f\"   Annualized Return: {metrics_df.loc[best_sharpe, 'Annualized Return']:.2%}\")\n",
    "print(f\"   Max Drawdown: {metrics_df.loc[best_sharpe, 'Max Drawdown']:.2%}\")\n",
    "\n",
    "print(\"\\n2. Highest Return Strategy:\")\n",
    "best_return = metrics_df['Annualized Return'].idxmax()\n",
    "print(f\"   Strategy: {best_return}\")\n",
    "print(f\"   Annualized Return: {metrics_df.loc[best_return, 'Annualized Return']:.2%}\")\n",
    "print(f\"   Volatility: {metrics_df.loc[best_return, 'Annualized Volatility']:.2%}\")\n",
    "\n",
    "print(\"\\n3. Lowest Risk Strategy (by Max Drawdown):\")\n",
    "lowest_dd = metrics_df['Max Drawdown'].idxmin()\n",
    "print(f\"   Strategy: {lowest_dd}\")\n",
    "print(f\"   Max Drawdown: {metrics_df.loc[lowest_dd, 'Max Drawdown']:.2%}\")\n",
    "print(f\"   Annualized Return: {metrics_df.loc[lowest_dd, 'Annualized Return']:.2%}\")\n",
    "\n",
    "print(\"\\n4. PPO Agent Performance:\")\n",
    "if 'PPO' in metrics_df.index:\n",
    "    ppo_metrics = metrics_df.loc['PPO']\n",
    "    print(f\"   Sharpe Ratio: {ppo_metrics['Sharpe Ratio']:.4f}\")\n",
    "    print(f\"   Annualized Return: {ppo_metrics['Annualized Return']:.2%}\")\n",
    "    print(f\"   Max Drawdown: {ppo_metrics['Max Drawdown']:.2%}\")\n",
    "    print(f\"   Average Turnover: {ppo_metrics['Average Turnover']:.4f}\")\n",
    "    \n",
    "    # Rank among all strategies\n",
    "    sharpe_rank = (metrics_df['Sharpe Ratio'] > ppo_metrics['Sharpe Ratio']).sum() + 1\n",
    "    print(f\"   Sharpe Ratio Rank: {sharpe_rank} out of {len(metrics_df)}\")\n",
    "\n",
    "print(\"\\n5. Key Observations:\")\n",
    "print(\"   - DRL agents learn adaptive trading policies from data\")\n",
    "print(\"   - Transaction costs significantly impact strategy performance\")\n",
    "print(\"   - Risk-adjusted metrics (Sharpe ratio) more meaningful than raw returns\")\n",
    "print(\"   - Portfolio diversification helps manage risk\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✓ Analysis Complete!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafad15b",
   "metadata": {},
   "source": [
    "## Additional Experiments\n",
    "\n",
    "Try these experiments to further explore the framework:\n",
    "\n",
    "1. **Different Assets**: Change `ASSETS` list to include different stocks or ETFs\n",
    "2. **Transaction Costs**: Vary `TRANSACTION_COST` to see impact on strategies\n",
    "3. **Training Duration**: Increase `TRAIN_TIMESTEPS` for better convergence\n",
    "4. **Network Architecture**: Modify `net_arch` in agent creation\n",
    "5. **Reward Functions**: Try different `reward_type` values\n",
    "6. **DDPG Agent**: Train and evaluate DDPG alongside PPO\n",
    "7. **Market Regimes**: Analyze performance in bull vs bear markets\n",
    "8. **Hyperparameter Tuning**: Optimize learning rates, batch sizes, etc.\n",
    "\n",
    "---\n",
    "\n",
    "**Disclaimer**: This is an academic research project for educational purposes only. Not financial advice. Do not use for real trading without proper validation."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
